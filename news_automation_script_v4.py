import feedparser
import requests
import json
import re
import openai
import os
import os.path
import datetime
import smtplib
import getpass
from email.mime.multipart import MIMEMultipart
from email.mime.text import MIMEText
from email.utils import formatdate
from email.header import Header
from googleapiclient.discovery import build
from google.oauth2.credentials import Credentials
from google_auth_oauthlib.flow import InstalledAppFlow
from google.auth.transport.requests import Request
import difflib

# ==============================================================================
# --- 1. ì‚¬ìš©ì ì„¤ì • (GitHub Actions Secretsì—ì„œ ìë™ìœ¼ë¡œ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤) ---
# ==============================================================================

# Google Alerts RSS ì£¼ì†Œ
GOOGLE_ALERTS_RSS_URLS = [
    "https://www.google.co.kr/alerts/feeds/14299983816346888060/2091321787487599294", #Satellite Communications
    "https://www.google.co.kr/alerts/feeds/14299983816346888060/7282625974461397688", #ìœ„ì„±í†µì‹ 
    "https://www.google.co.kr/alerts/feeds/14299983816346888060/2091321787487600193", #Non terrestrial Networks
    "https://www.google.co.kr/alerts/feeds/14299983816346888060/2091321787487600258", #3GPP
    "https://www.google.co.kr/alerts/feeds/14299983816346888060/6144919849490706746", #6G
    "https://www.google.co.kr/alerts/feeds/14299983816346888060/13972650129806487379", #ì €ê¶¤ë„
    "https://www.google.co.kr/alerts/feeds/14299983816346888060/5231113795348014351", #FCC 47 CFR PArt 25
    "https://www.google.co.kr/alerts/feeds/14299983816346888060/6144919849490708240", #low Earth orbit
    "https://www.google.co.kr/alerts/feeds/14299983816346888060/12348804382892789873", #ì£¼íŒŒìˆ˜
    "https://www.google.co.kr/alerts/feeds/14299983816346888060/6144919849490708655", #AI-RAN
    "https://www.google.co.kr/alerts/feeds/14299983816346888060/270492137594840372", #AI-RAN
    "https://www.google.co.kr/alerts/feeds/14299983816346888060/2496376606356182211", #AI network
    "https://www.google.co.kr/alerts/feeds/14299983816346888060/2496376606356181274", #ITU-R
    "https://www.google.co.kr/alerts/feeds/14299983816346888060/18373922797329225191", #ISAC
    "https://www.google.co.kr/alerts/feeds/14299983816346888060/2496376606356184244", #IMT-2030
]

# Naver ê²€ìƒ‰ í‚¤ì›Œë“œ
NAVER_QUERIES = [
    "ìœ„ì„±í†µì‹ ", "satellite communication",
    "ì €ê¶¤ë„", "LEO",
    "ICT í‘œì¤€", "ICT standardization",
    "ì£¼íŒŒìˆ˜ ì •ì±…", "spectrum policy",
    "3GPP", "ITU", "FCC", "ofcom"
]

# GitHub Secretsë¥¼ í†µí•´ í™˜ê²½ ë³€ìˆ˜ì—ì„œ API í‚¤ì™€ ì„¤ì •ê°’ ë¶ˆëŸ¬ì˜¤ê¸°
NAVER_CLIENT_ID = os.environ.get("NAVER_CLIENT_ID")
NAVER_CLIENT_SECRET = os.environ.get("NAVER_CLIENT_SECRET")
OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY")
SENDER_EMAIL = os.environ.get("SENDER_EMAIL")
GMAIL_PASSWORD = os.environ.get("GMAIL_PASSWORD")
RECEIVER_EMAIL = [email.strip() for email in os.environ.get("RECEIVER_EMAIL", "").split(',') if email.strip()]

# Google API ì„¤ì •
SCOPES = ['https://www.googleapis.com/auth/documents', 'https://www.googleapis.com/auth/drive']

# ==============================================================================
# --- í—¬í¼ í•¨ìˆ˜: URL ìµœì¢… ëª©ì ì§€ ì¶”ì  (ê³ ë„í™”) ---
# ==============================================================================
def get_final_url(url):
    """ë¦¬ë””ë ‰ì…˜ì„ ì¶”ì í•˜ì—¬ ìµœì¢… URLì„ ì°¾ì•„ë‚´ëŠ” ê³ ë„í™”ëœ í•¨ìˆ˜"""
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        response = requests.head(url, headers=headers, allow_redirects=True, timeout=10)
        response.raise_for_status()
        return response.url
    except requests.RequestException:
        try:
            response = requests.get(url, headers=headers, allow_redirects=True, timeout=10)
            response.raise_for_status()
            return response.url
        except requests.RequestException as e:
            return url

# ==============================================================================
# --- 2. ë‰´ìŠ¤ ìˆ˜ì§‘ í•¨ìˆ˜ (ì¤‘ë³µ ì œê±° ë¡œì§ ê°œì„ ) ---
# ==============================================================================
def get_news_data():
    """ì—¬ëŸ¬ RSS í”¼ë“œì™€ í‚¤ì›Œë“œì—ì„œ ë‰´ìŠ¤ë¥¼ ìˆ˜ì§‘í•˜ê³  ì¤‘ë³µì„ ì •í™•í•˜ê²Œ ì œê±°í•˜ëŠ” í•¨ìˆ˜"""
    news_list = []
    
    print("\n- Google Alertsì—ì„œ ë‰´ìŠ¤ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤...")
    for url in GOOGLE_ALERTS_RSS_URLS:
        if not url.strip(): continue
        try:
            feed = feedparser.parse(url)
            for entry in feed.entries:
                raw_link = entry.link.split("&url=")[1] if "&url=" in entry.link else entry.link
                final_link = get_final_url(raw_link)
                published_date = datetime.datetime(*entry.published_parsed[:6]).strftime('%Y-%m-%d') if hasattr(entry, 'published_parsed') else "ë‚ ì§œ ì •ë³´ ì—†ìŒ"
                news_list.append({"title": entry.title, "link": final_link, "published": published_date, "source": "Google Alerts"})
        except Exception as e:
            print(f"  (ê²½ê³ ) êµ¬ê¸€ ì•Œë¦¬ë¯¸ RSS ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨ ({url}): {e}")

    print("- Naver Newsì—ì„œ ë‰´ìŠ¤ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤...")
    for query in NAVER_QUERIES:
        if not query.strip(): continue
        try:
            naver_url = "https://openapi.naver.com/v1/search/news.json"
            headers = {"X-Naver-Client-Id": NAVER_CLIENT_ID, "X-Naver-Client-Secret": NAVER_CLIENT_SECRET}
            params = {"query": query, "display": 10, "sort": "date"}
            response = requests.get(naver_url, headers=headers, params=params)
            response.raise_for_status()
            data = response.json()
            for item in data.get("items", []):
                clean_title = re.sub('<[^>]*>', '', item["title"])
                published_date = datetime.datetime.strptime(item['pubDate'], '%a, %d %b %Y %H:%M:%S +0900').strftime('%Y-%m-%d')
                raw_link = item.get("originallink", item["link"])
                news_list.append({"title": clean_title, "link": raw_link, "published": published_date, "source": "Naver News"})
        except Exception as e:
            print(f"  (ê²½ê³ ) ë„¤ì´ë²„ ë‰´ìŠ¤ API ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨ ({query}): {e}")

    news_list.sort(key=lambda x: x['published'], reverse=True)
    unique_news_items = []
    seen_links = set()
    seen_titles = []

    for item in news_list:
        normalized_link = re.sub(r'^https?:\/\/(www\.)?', '', item['link']).rstrip('/')
        if normalized_link in seen_links:
            continue
        
        is_similar = False
        for seen_title in seen_titles:
            similarity = difflib.SequenceMatcher(None, item['title'], seen_title).ratio()
            if similarity > 0.85:
                is_similar = True
                break
        
        if not is_similar:
            unique_news_items.append(item)
            seen_links.add(normalized_link)
            seen_titles.append(item['title'])
            
    return unique_news_items

# ==============================================================================
# --- 3. AI ë‰´ìŠ¤ ì„ ë³„ í•¨ìˆ˜ ---
# ==============================================================================
def filter_news_by_ai(news_items):
    """AIë¥¼ ì‚¬ìš©í•´ ì •ì±… ì…ì•ˆìì—ê²Œ ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ë‰´ìŠ¤ë¥¼ ì„ ë³„í•˜ëŠ” í•¨ìˆ˜"""
    print("\n[ğŸš€ ì‘ì—… ì¤‘] AIê°€ ì •ì±… ì…ì•ˆìë¥¼ ìœ„í•´ ë‰´ìŠ¤ë¥¼ ì„ ë³„í•˜ê³  ìˆìŠµë‹ˆë‹¤...")
    if not OPENAI_API_KEY or not OPENAI_API_KEY.startswith("sk-"):
        print("  (ê²½ê³ ) OpenAI API í‚¤ê°€ ì—†ì–´ ë‰´ìŠ¤ ì„ ë³„ì„ ê±´ë„ˆë›°ê³  ìµœì‹  ë‰´ìŠ¤ 20ê°œë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.")
        return news_items[:20]

    client = openai.OpenAI(api_key=OPENAI_API_KEY)
    formatted_news_list = ""
    for i, item in enumerate(news_items):
        formatted_news_list += f"{i}: {item['title']}\n"

    prompt = f"""
    ë‹¹ì‹ ì€ ICT í‘œì¤€ ì •ì±… ìµœê³  ì „ë¬¸ê°€ì˜ ìˆ˜ì„ ë³´ì¢Œê´€ì…ë‹ˆë‹¤.
    ë‹¹ì‹ ì˜ ì„ë¬´ëŠ” ì•„ë˜ ë‰´ìŠ¤ ëª©ë¡ì—ì„œ ë¨¼ì € ë‚´ìš©ì´ ì¤‘ë³µë˜ëŠ” ê¸°ì‚¬ë“¤ì„ ì œê±°í•œ ë’¤, 'í‘œì¤€ ì •ì±… ì…ì•ˆì'ì˜ ê´€ì ì—ì„œ ê°€ì¥ ì¤‘ìš”í•œ ë‰´ìŠ¤ 20ê°œë¥¼ ì„ ë³„í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

    [ì‘ì—… ì ˆì°¨]
    1. **ì¤‘ë³µ ì œê±°**: ì•„ë˜ ë‰´ìŠ¤ ëª©ë¡ì—ì„œ ì‚¬ì‹¤ìƒ ë™ì¼í•œ ì‚¬ê±´ì´ë‚˜ ì£¼ì œë¥¼ ë‹¤ë£¨ëŠ” ê¸°ì‚¬ë“¤ì„ í•˜ë‚˜ì˜ ê·¸ë£¹ìœ¼ë¡œ ë¬¶ê³ , ê° ê·¸ë£¹ì—ì„œ ê°€ì¥ í¬ê´„ì ì¸ ëŒ€í‘œ ê¸°ì‚¬ í•˜ë‚˜ë§Œ ë‚¨ê¹ë‹ˆë‹¤.
    2. **ìµœì¢… ì„ ë³„**: ì¤‘ë³µì´ ì œê±°ëœ ë‰´ìŠ¤ ëª©ë¡ì—ì„œ, ì•„ë˜ [ì„ ë³„ ìµœìš°ì„  ê¸°ì¤€]ì— ë”°ë¼ ê°€ì¥ ì¤‘ìš”í•œ ë‰´ìŠ¤ 20ê°œë¥¼ ìµœì¢…ì ìœ¼ë¡œ ì„ ë³„í•©ë‹ˆë‹¤.

    [ì„ ë³„ ìµœìš°ì„  ê¸°ì¤€]
    ì •ì±…ì  ì¤‘ìš”ë„ë¥¼ ìµœìš°ì„ ìœ¼ë¡œ ê³ ë ¤í•˜ë©°, íŠ¹íˆ ì•„ë˜ ì£¼ì œë¥¼ ë‹¤ë£¨ëŠ” êµ­ë‚´ì™¸ ë‰´ìŠ¤ì— ë†’ì€ ê°€ì¤‘ì¹˜ë¥¼ ë¶€ì—¬í•©ë‹ˆë‹¤.
    - **í•´ì™¸ ì£¼ìš”êµ­ ì •ì±…/ê·œì œ**: ë¯¸êµ­(FCC), ìœ ëŸ½(ETSI), ì˜êµ­(Ofcom) ë“± í•´ì™¸ ì£¼ìš” ICT ê·œì œê¸°ê´€ ë° ì •ì±… ë‹¹êµ­ì˜ ë²•ì•ˆ, ê·œì œ, ì •ì±… ë³€í™”, ê¸€ë¡œë²Œ ICT ê±°ë²„ë„ŒìŠ¤ ë° ê·œì œ í”„ë ˆì„ì›Œí¬ ë³€í™”
    - **êµ­ì œ í‘œì¤€í™” ë™í–¥**: 3GPP, ITU, IEEE, ISO/IEC JTC 1 ë“± êµ­ì œ í‘œì¤€í™” ê¸°êµ¬ì˜ ì˜ì‚¬ê²°ì • ê²°ê³¼, ì°¨ê¸° ì˜ì œ, ì£¼ìš” í•©ì˜ ì‚¬í•­, ì°¨ì„¸ëŒ€ ê¸°ìˆ (6G, AI, ìœ„ì„±í†µì‹ , ììœ¨ì£¼í–‰, ì–‘ ë“±) í‘œì¤€í™” ë°©í–¥ì„±
    - **êµ­ë‚´ ì •ë¶€ ê³„íš ë° ë°œí‘œ**: ê³¼ê¸°ì •í†µë¶€, ë°©í†µìœ„, ì‚°ì—…ìì› ë“± êµ­ë‚´ ì •ë¶€ ë¶€ì²˜ì˜ ì •ì±… ë°œí‘œ, ë²•Â·ì œë„ ì‹ ì„¤Â·ê°œì •, êµ­ê°€ R&D ì „ëµ, ë””ì§€í„¸ ê·œì œ, ê³µê³µì•ˆì „í†µì‹ , ì£¼íŒŒìˆ˜ ì •ì±… ë“± í•µì‹¬ ì •ì±…
    - **ì‚°ì—…ê³„ í•µì‹¬ ë™í–¥**: ICT ì‚°ì—… ë° ì‹œì¥ íŒë„ì— í° ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” êµ­ë‚´ì™¸ ê¸°ì—…ì˜ ê¸°ìˆ  ê°œë°œ ë° ì‚¬ì—… ì „ëµ
    - **ì •ì±… ë¹„íŒ ë° ëŒ€ì•ˆ**: í˜„ì¬ ì •ì±…ì˜ ë¬¸ì œì ì„ ì§€ì í•˜ê±°ë‚˜ ìƒˆë¡œìš´ ëŒ€ì•ˆì„ ì œì‹œí•˜ëŠ” ê¸°ì‚¬
    - **TTA ë³´ë„ìë£Œ**: TTA ê³µì‹ ë³´ë„ìë£Œ, í‘œì¤€ ì œì •Â·ê°œì • ë°œí‘œ, ì†ìŠ¹í˜„ íšŒì¥ ë“± ì£¼ìš” ì¸ì‚¬ì˜ ë°œì–¸, ì¸í„°ë·°, ê¸°ê³ 


    [ë‰´ìŠ¤ ëª©ë¡]
    {formatted_news_list}

    [ìš”ì²­]
    ìœ„ ì ˆì°¨ì™€ ê¸°ì¤€ì— ë”°ë¼ ìµœì¢…ì ìœ¼ë¡œ ì„ ë³„ëœ ë‰´ìŠ¤ì˜ ë²ˆí˜¸ 20ê°œë§Œ ì‰¼í‘œ(,)ë¡œ êµ¬ë¶„í•˜ì—¬ ì‘ë‹µí•´ ì£¼ì‹­ì‹œì˜¤.
    ì˜ˆì‹œ: 3, 8, 12, 15, 21, 23, 25, 30, 31, 33, 40, 41, 42, 45, 50, 51, 52, 53, 54, 55
    (ì„¤ëª…ì´ë‚˜ ë‹¤ë¥¸ í…ìŠ¤íŠ¸ëŠ” ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”. ë²ˆí˜¸ë§Œ ì‘ë‹µí•´ì•¼ í•©ë‹ˆë‹¤.)
    """

    try:
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ICT í‘œì¤€ ì •ì±… ì „ë¬¸ê°€ì˜ ìœ ëŠ¥í•œ ë³´ì¢Œê´€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ë‰´ìŠ¤ ëª©ë¡ì—ì„œ ì¤‘ë³µì„ ì œê±°í•˜ê³ , ì •ì±…ì  ì¤‘ìš”ë„ê°€ ê°€ì¥ ë†’ì€ 20ê°œë¥¼ ê³¨ë¼ ë²ˆí˜¸ë§Œ ì‘ë‹µí•©ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.0,
        )
        selected_indices_str = response.choices[0].message.content
        print(f"  > AIê°€ ì„ ë³„í•œ ë‰´ìŠ¤ ì¸ë±ìŠ¤: {selected_indices_str}")
        selected_indices = [int(i.strip()) for i in selected_indices_str.split(',')]
        filtered_news = [news_items[i] for i in selected_indices if i < len(news_items)]
        if not filtered_news: raise ValueError("AIê°€ ìœ íš¨í•œ ì¸ë±ìŠ¤ë¥¼ ë°˜í™˜í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return filtered_news
    except Exception as e:
        print(f"  (ê²½ê³ ) AI ë‰´ìŠ¤ ì„ ë³„ ì‹¤íŒ¨: {e}. ìµœì‹  ë‰´ìŠ¤ 20ê°œë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
        return news_items[:20]

# ==============================================================================
# --- 4. AI ì‹¬ì¸µ ë¶„ì„ í•¨ìˆ˜ (ë³´ê³ ì„œ í˜•ì‹ êµ¬ì²´í™”) ---
# ==============================================================================
def analyze_news_with_ai(news_item):
    """AIì—ê²Œ ë‰´ìŠ¤ë¥¼ ë³´ë‚´ êµ¬ì²´í™”ëœ ì „ë¬¸ê°€ ë³´ê³ ì„œ í˜•ì‹ìœ¼ë¡œ ì‹¬ì¸µ ë¶„ì„ì„ ìš”ì²­í•˜ëŠ” í•¨ìˆ˜"""
    if not OPENAI_API_KEY or not OPENAI_API_KEY.startswith("sk-"):
        return "OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ ë¶„ì„ì„ ê±´ë„ˆëœë‹ˆë‹¤."
        
    client = openai.OpenAI(api_key=OPENAI_API_KEY)
    prompt = f"""
    ë‹¹ì‹ ì€ 20ë…„ ê²½ë ¥ì˜ ICT í‘œì¤€ ë° ì •ì±… ë¶„ì•¼ ìµœê³  ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
    ì•„ë˜ ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ ë¶„ì„í•˜ì—¬, ë‹¤ìŒ 4ê°€ì§€ í•­ëª©ìœ¼ë¡œ êµ¬ì„±ëœ ì „ë¬¸ê°€ ë³´ê³ ì„œë¥¼ ì‘ì„±í•´ ì£¼ì‹­ì‹œì˜¤.
    ëª¨ë“  ë‚´ìš©ì€ ì¤‘í•™ìƒë„ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ëª…í™•í•˜ê³  ì‰¬ìš´ ì–¸ì–´ë¥¼ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.

    [ë‰´ìŠ¤ ì •ë³´]
    - ë‰´ìŠ¤ ì œëª©: {news_item['title']}
    - ì›ë¬¸ ë§í¬: {news_item['link']}

    [ë³´ê³ ì„œ ì‘ì„± í˜•ì‹]
    1. **í•µì‹¬ ìš”ì•½:** (ê¸°ì‚¬ ì „ì²´ ë‚´ìš©ì„ ë‹¨ í•œ ë¬¸ì¥ìœ¼ë¡œ ì••ì¶•í•˜ì—¬ ìš”ì•½)
    2. **ì£¼ìš” ë‚´ìš©:** (ê¸°ì‚¬ì˜ í•µì‹¬ ì‚¬ì‹¤ê³¼ ì •ë³´ë¥¼ 3ê°œ í•­ëª©ìœ¼ë¡œ ë‚˜ëˆ„ì–´ç®‡æ¡æ›¸ã(bullet point)ë¡œ ì •ë¦¬)
       - 
       - 
       - 
    3. **ì •ì±…ì  ì‹œì‚¬ì :** (ì´ ë‰´ìŠ¤ê°€ ICT í‘œì¤€, ê·œì œ, ì •ë¶€ ì •ì±…ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì´ë‚˜ ì˜ë¯¸ë¥¼ ë¶„ì„)
    4. **ê¸°ëŒ€ íš¨ê³¼ ë° ì „ë§:** (í–¥í›„ ê¸°ìˆ  ë°œì „, ì‹œì¥ ë³€í™”, ì‚¬íšŒì  íŒŒê¸‰ íš¨ê³¼ ë“±ì„ ì˜ˆì¸¡)
    """
    try:
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ICT í‘œì¤€ ì •ì±… ë¶„ì„ ìµœê³  ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ëª¨ë“  ë‹µë³€ì€ ì§€ì •ëœ 4ê°€ì§€ ë³´ê³ ì„œ í˜•ì‹ì— ë§ì¶°, ì‰½ê³  ëª…í™•í•œ ì–¸ì–´ë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.5, max_tokens=1024,
        )
        return response.choices[0].message.content
    except Exception as e:
        print(f"  (ê²½ê³ ) AI ì‹¬ì¸µ ë¶„ì„ ì‹¤íŒ¨ ({news_item['title']}): {e}")
        return "AI ì‹¬ì¸µ ë¶„ì„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."

# ==============================================================================
# --- 5. êµ¬ê¸€ ë¬¸ì„œ ìƒì„± í•¨ìˆ˜ (API ì˜¤ë¥˜ ìˆ˜ì •) ---
# ==============================================================================
def get_google_services():
    """Google Docsì™€ Drive API ì„œë¹„ìŠ¤ë¥¼ ì¸ì¦í•˜ê³  ìƒì„±í•˜ëŠ” í•¨ìˆ˜"""
    creds = None
    if os.path.exists('token.json'):
        creds = Credentials.from_authorized_user_file('token.json', SCOPES)
    if not creds or not creds.valid:
        if creds and creds.expired and creds.refresh_token:
            try:
                creds.refresh(Request())
            except Exception as e:
                print(f" (ì •ë³´) í† í° ê°±ì‹  ì‹¤íŒ¨: {e}. 'token.json'ì„ ì‚­ì œí•˜ê³  ë‹¤ì‹œ ì¸ì¦ì„ ì‹œë„í•©ë‹ˆë‹¤.")
                if os.path.exists('token.json'):
                    os.remove('token.json')
                creds = None
    
    if not creds:
        flow = InstalledAppFlow.from_client_secrets_file('credentials.json', SCOPES)
        creds = flow.run_local_server(port=0)
        with open('token.json', 'w') as token:
            token.write(creds.to_json())
            
    docs_service = build('docs', 'v1', credentials=creds)
    drive_service = build('drive', 'v3', credentials=creds)
    return docs_service, drive_service

def generate_google_doc_report(analyzed_data):
    try:
        docs_service, drive_service = get_google_services()
    except FileNotFoundError:
        print("  (ì˜¤ë¥˜) 'credentials.json' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. êµ¬ê¸€ ì¸ì¦ ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš”.")
        return None, None
    except Exception as e:
        print(f"  (ì˜¤ë¥˜) êµ¬ê¸€ ì„œë¹„ìŠ¤ ì—°ê²°ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}")
        return None, None
        
    current_date = datetime.date.today().strftime('%Yë…„ %mì›” %dì¼')
    document_title = f"ICT ì£¼ìš” ê¸°ìˆ  ë™í–¥ ë³´ê³ ì„œ ({current_date})"
    
    try:
        document = docs_service.documents().create(body={'title': document_title}).execute()
        document_id = document.get('documentId')
        
        permission = {'type': 'anyone', 'role': 'reader'}
        drive_service.permissions().create(fileId=document_id, body=permission).execute()
        print("  > ë¬¸ì„œ ì ‘ê·¼ ê¶Œí•œì„ ê³µê°œë¡œ ì„¤ì •í–ˆìŠµë‹ˆë‹¤.")

        document_url = f"https://docs.google.com/document/d/{document_id}/edit"
        print(f"  > ìƒˆ ë¬¸ì„œê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤: {document_url}")

        requests = []
        index = 1
        
        requests.append({'insertText': {'location': {'index': index}, 'text': document_title + '\n'}})
        requests.append({'updateParagraphStyle': {'range': {'startIndex': 1, 'endIndex': len(document_title)+1}, 'paragraphStyle': {'namedStyleType': 'TITLE', 'alignment': 'CENTER', 'spaceBelow': {'magnitude': 12, 'unit': 'PT'}}, 'fields': '*'}})
        index += len(document_title) + 1

        disclaimer = "ë³¸ ë³´ê³ ì„œëŠ” AIê°€ ì£¼ìš” ë‰´ìŠ¤ë¥¼ ë¶„ì„í•˜ì—¬ ì‘ì„±í–ˆìœ¼ë©°, ê°œì¸ì ì¸ ì˜ê²¬ì„ í¬í•¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n\n"
        requests.append({'insertText': {'location': {'index': index}, 'text': disclaimer}})
        requests.append({'updateParagraphStyle': {'range': {'startIndex': index, 'endIndex': index + len(disclaimer)}, 'paragraphStyle': {'alignment': 'CENTER'}, 'fields': 'alignment'}})
        requests.append({'updateTextStyle': {'range': {'startIndex': index, 'endIndex': index + len(disclaimer)}, 'textStyle': {'fontSize': {'magnitude': 9, 'unit': 'PT'}, 'foregroundColor': {'color': {'rgbColor': {'red': 0.4, 'green': 0.4, 'blue': 0.4}}}}, 'fields': 'fontSize,foregroundColor'}})
        index += len(disclaimer)

        for i, data in enumerate(analyzed_data):
            news_title = f"{i+1}. {data['title']}\n"
            requests.append({'insertText': {'location': {'index': index}, 'text': news_title}})
            
            # --- ğŸ’¡ ì˜¤ë¥˜ ìˆ˜ì • ì§€ì  ---
            # borderBottom ê°ì²´ì— 'dashStyle': 'SOLID'ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.
            border_bottom_style = {
                'width': {'magnitude': 1, 'unit': 'PT'},
                'padding': {'magnitude': 2, 'unit': 'PT'},
                'color': {'color': {'rgbColor': {'red': 0.8, 'green': 0.8, 'blue': 0.8}}},
                'dashStyle': 'SOLID' 
            }
            
            requests.append({'updateParagraphStyle': {
                'range': {'startIndex': index, 'endIndex': index + len(news_title)},
                'paragraphStyle': {
                    'namedStyleType': 'HEADING_1',
                    'spaceAbove': {'magnitude': 18, 'unit': 'PT'},
                    'spaceBelow': {'magnitude': 4, 'unit': 'PT'},
                    'borderBottom': border_bottom_style
                },
                'fields': 'namedStyleType,spaceAbove,spaceBelow,borderBottom'
            }})
            index += len(news_title)
            
            meta_text = f"ì¶œì²˜: {data['source']} | ë°œí–‰ì¼: {data['published']}\n"
            requests.append({'insertText': {'location': {'index': index}, 'text': meta_text}})
            requests.append({'updateParagraphStyle': {'range': {'startIndex': index, 'endIndex': index + len(meta_text)},'paragraphStyle': {'spaceBelow': {'magnitude': 6, 'unit': 'PT'}},'fields': 'spaceBelow'}})
            requests.append({'updateTextStyle': {'range': {'startIndex': index, 'endIndex': index + len(meta_text)}, 'textStyle': {'fontSize': {'magnitude': 9, 'unit': 'PT'}, 'foregroundColor': {'color': {'rgbColor': {'red': 0.5, 'green': 0.5, 'blue': 0.5}}}}, 'fields': 'fontSize,foregroundColor'}})
            index += len(meta_text)

            link_text = f"ì›ë³¸ ë§í¬ ë°”ë¡œê°€ê¸°\n\n"
            requests.append({'insertText': {'location': {'index': index}, 'text': link_text}})
            requests.append({'updateTextStyle': {'range': {'startIndex': index, 'endIndex': index + len(link_text)}, 'textStyle': {'fontSize': {'magnitude': 9, 'unit': 'PT'}, 'link': {'url': data['link']}}, 'fields': 'fontSize,link'}})
            index += len(link_text)
            
            analysis_text = data.get('analysis_result', '')
            
            sections = {
                "í•µì‹¬ ìš”ì•½": re.search(r'\*\*(í•µì‹¬ ìš”ì•½):\*\*\s*(.*?)(?=\s*\*\*|\Z)', analysis_text, re.DOTALL),
                "ì£¼ìš” ë‚´ìš©": re.search(r'\*\*(ì£¼ìš” ë‚´ìš©):\*\*\s*(.*?)(?=\s*\*\*|\Z)', analysis_text, re.DOTALL),
                "ì •ì±…ì  ì‹œì‚¬ì ": re.search(r'\*\*(ì •ì±…ì  ì‹œì‚¬ì ):\*\*\s*(.*?)(?=\s*\*\*|\Z)', analysis_text, re.DOTALL),
                "ê¸°ëŒ€ íš¨ê³¼ ë° ì „ë§": re.search(r'\*\*(ê¸°ëŒ€ íš¨ê³¼ ë° ì „ë§):\*\*\s*(.*?)(?=\s*\*\*|\Z)', analysis_text, re.DOTALL)
            }
            
            for title, match in sections.items():
                if match:
                    section_title = f"{title}\n"
                    requests.append({'insertText': {'location': {'index': index}, 'text': section_title}})
                    requests.append({'updateParagraphStyle': {'range': {'startIndex': index, 'endIndex': index + len(section_title)}, 'paragraphStyle': {'namedStyleType': 'HEADING_3', 'spaceAbove': {'magnitude': 12, 'unit': 'PT'}, 'spaceBelow': {'magnitude': 3, 'unit': 'PT'}}, 'fields': '*'}})
                    index += len(section_title)
                    
                    content_body = match.group(2).strip().replace("   -", "-").replace("  -", "-") + "\n\n"
                    requests.append({'insertText': {'location': {'index': index}, 'text': content_body}})
                    if "- " in content_body:
                         requests.append({'createParagraphBullets': {'range': {'startIndex': index, 'endIndex': index + len(content_body)}, 'bulletPreset': 'BULLET_DISC_CIRCLE_SQUARE'}})
                    index += len(content_body)

        docs_service.documents().batchUpdate(documentId=document_id, body={'requests': requests}).execute()
        return document_url, document_title
    except Exception as e:
        print(f"  (ì˜¤ë¥˜) êµ¬ê¸€ ë¬¸ì„œ ìƒì„±/ìŠ¤íƒ€ì¼ë§ ì‹¤íŒ¨: {e}")
        return None, None

# ==============================================================================
# --- 6. Gmail ì „ì†¡ í•¨ìˆ˜ (ê¸°ì¡´ê³¼ ë™ì¼) ---
# ==============================================================================
def send_gmail_report(report_title, analyzed_data, doc_url, other_news):
    # ì´ í•¨ìˆ˜ëŠ” ìˆ˜ì • ì—†ì´ ê·¸ëŒ€ë¡œ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.
    # ... (ê¸°ì¡´ send_gmail_report í•¨ìˆ˜ ì½”ë“œ)
    pass

# ==============================================================================
# --- 7. ë©”ì¸ ì‹¤í–‰ ë¶€ë¶„ (ê¸°ì¡´ê³¼ ë™ì¼) ---
# ==============================================================================
if __name__ == "__main__":
    print("==============================================")
    print("ğŸ¤– AI ë‰´ìŠ¤ ë¦¬í¬íŠ¸ ìë™ ìƒì„± ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.")
    print("==============================================")
    
    print("\n[ğŸš€ ì‘ì—… ì‹œì‘] ë‰´ìŠ¤ ìˆ˜ì§‘ ë° ì¤‘ë³µ ì œê±°ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
    unique_news_items = get_news_data()
    print(f"  > ì´ {len(unique_news_items)}ê°œì˜ ê³ ìœ í•œ ë‰´ìŠ¤ë¥¼ ìˆ˜ì§‘í–ˆìŠµë‹ˆë‹¤.")
    
    news_to_analyze = filter_news_by_ai(unique_news_items)
    print(f"  > AIê°€ ì„ ë³„í•œ {len(news_to_analyze)}ê°œì˜ í•µì‹¬ ë‰´ìŠ¤ë¥¼ ì‹¬ì¸µ ë¶„ì„í•©ë‹ˆë‹¤.")
    
    analyzed_links = {item['link'] for item in news_to_analyze}
    other_news = [item for item in unique_news_items if item['link'] not in analyzed_links]
    
    analyzed_results = []
    if news_to_analyze:
        print("\n[ğŸš€ ì‘ì—… ì¤‘] ì„ íƒëœ ë‰´ìŠ¤ì— ëŒ€í•œ ì‹¬ì¸µ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
        for i, item in enumerate(news_to_analyze):
            print(f"  ({i+1}/{len(news_to_analyze)}) ë¶„ì„ ì¤‘: {item['title'][:40]}...")
            analysis = analyze_news_with_ai(item)
            item['analysis_result'] = analysis
            analyzed_results.append(item)
            
    if analyzed_results:
        print("\n[ğŸš€ ì‘ì—… ì¤‘] êµ¬ê¸€ ë¬¸ì„œ ë³´ê³ ì„œë¥¼ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤...")
        generated_doc_url, report_title = generate_google_doc_report(analyzed_results)
        
        if report_title:
            print("\n[ğŸš€ ì‘ì—… ì¤‘] ìƒì„±ëœ ë¦¬í¬íŠ¸ë¥¼ ì´ë©”ì¼ë¡œ ë°œì†¡í•©ë‹ˆë‹¤...")
            # send_gmail_report(report_title, analyzed_results, generated_doc_url, other_news)
            print("   (ì •ë³´) ì´ë©”ì¼ ë°œì†¡ì€ ì£¼ì„ ì²˜ë¦¬ë˜ì–´ ìˆìŠµë‹ˆë‹¤. í•„ìš” ì‹œ ì£¼ì„ì„ í•´ì œí•˜ì„¸ìš”.")

    print("\n==============================================")
    print("ğŸ‰ ëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    print("==============================================")
