import feedparser
import requests
import json
import re
import openai
import os
import os.path
import datetime
import smtplib
import getpass
from email.mime.multipart import MIMEMultipart
from email.mime.text import MIMEText
from email.utils import formatdate
from email.header import Header
from googleapiclient.discovery import build
from google.oauth2.credentials import Credentials
from google_auth_oauthlib.flow import InstalledAppFlow
from google.auth.transport.requests import Request
import difflib

# ==============================================================================
# --- 1. ì‚¬ìš©ì ì„¤ì • (GitHub Actions Secretsì—ì„œ ìë™ìœ¼ë¡œ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤) ---
# ==============================================================================

# Google Alerts RSS ì£¼ì†Œ
GOOGLE_ALERTS_RSS_URLS = [
    "https://www.google.co.kr/alerts/feeds/14299983816346888060/2091321787487599294", #Satellite Communications
    "https://www.google.co.kr/alerts/feeds/14299983816346888060/7282625974461397688", #ìœ„ì„±í†µì‹ 
    "https://www.google.co.kr/alerts/feeds/14299983816346888060/2091321787487600193", #Non terrestrial Networks
    "https://www.google.co.kr/alerts/feeds/14299983816346888060/2091321787487600258", #3GPP
    "https://www.google.co.kr/alerts/feeds/14299983816346888060/6144919849490706746", #6G
    "https://www.google.co.kr/alerts/feeds/14299983816346888060/13972650129806487379", #ì €ê¶¤ë„
    "https://www.google.co.kr/alerts/feeds/14299983816346888060/5231113795348014351", #FCC 47 CFR PArt 25
    "https://www.google.co.kr/alerts/feeds/14299983816346888060/6144919849490708240", #low Earth orbit
    "https://www.google.co.kr/alerts/feeds/14299983816346888060/12348804382892789873", #ì£¼íŒŒìˆ˜
    "https://www.google.co.kr/alerts/feeds/14299983816346888060/6144919849490708655", #AI-RAN
    "https://www.google.co.kr/alerts/feeds/14299983816346888060/270492137594840372", #AI-RAN
    "https://www.google.co.kr/alerts/feeds/14299983816346888060/2496376606356182211", #AI network
    "https://www.google.co.kr/alerts/feeds/14299983816346888060/2496376606356181274", #ITU-R
    "https://www.google.co.kr/alerts/feeds/14299983816346888060/18373922797329225191", #ISAC
    "https://www.google.co.kr/alerts/feeds/14299983816346888060/2496376606356184244", #IMT-2030
]

# Naver ê²€ìƒ‰ í‚¤ì›Œë“œ
NAVER_QUERIES = [
    "ìœ„ì„±í†µì‹ ", "satellite communication",
    "ì €ê¶¤ë„", "LEO",
    "ICT í‘œì¤€", "ICT standardization",
    "ì£¼íŒŒìˆ˜ ì •ì±…", "spectrum policy",
    "3GPP", "ITU", "FCC", "ofcom"
]

# GitHub Secretsë¥¼ í†µí•´ í™˜ê²½ ë³€ìˆ˜ì—ì„œ API í‚¤ì™€ ì„¤ì •ê°’ ë¶ˆëŸ¬ì˜¤ê¸°
NAVER_CLIENT_ID = os.environ.get("NAVER_CLIENT_ID")
NAVER_CLIENT_SECRET = os.environ.get("NAVER_CLIENT_SECRET")
OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY")
SENDER_EMAIL = os.environ.get("SENDER_EMAIL")
GMAIL_PASSWORD = os.environ.get("GMAIL_PASSWORD")
RECEIVER_EMAIL = [email.strip() for email in os.environ.get("RECEIVER_EMAIL", "").split(',') if email.strip()]

# Google API ì„¤ì •
SCOPES = ['https://www.googleapis.com/auth/documents', 'https://www.googleapis.com/auth/drive']

# ==============================================================================
# --- í—¬í¼ í•¨ìˆ˜: URL ìµœì¢… ëª©ì ì§€ ì¶”ì  (ê³ ë„í™”) ---
# ==============================================================================
def get_final_url(url):
    """ë¦¬ë””ë ‰ì…˜ì„ ì¶”ì í•˜ì—¬ ìµœì¢… URLì„ ì°¾ì•„ë‚´ëŠ” ê³ ë„í™”ëœ í•¨ìˆ˜"""
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        response = requests.head(url, headers=headers, allow_redirects=True, timeout=10)
        response.raise_for_status()
        return response.url
    except requests.RequestException:
        try:
            response = requests.get(url, headers=headers, allow_redirects=True, timeout=10)
            response.raise_for_status()
            return response.url
        except requests.RequestException as e:
            return url

# ==============================================================================
# --- 2. ë‰´ìŠ¤ ìˆ˜ì§‘ í•¨ìˆ˜ (ë‹¨ìˆœ ìˆ˜ì§‘ ë° ë§í¬ ê¸°ë°˜ ì¤‘ë³µ ì œê±°) ---
# ==============================================================================
def get_news_data():
    """ì—¬ëŸ¬ RSS í”¼ë“œì™€ í‚¤ì›Œë“œì—ì„œ ë‰´ìŠ¤ë¥¼ ìˆ˜ì§‘í•˜ê³  1ì°¨ ì¤‘ë³µì„ ì œê±°í•˜ëŠ” í•¨ìˆ˜"""
    news_list = []
    
    print("\n- Google Alertsì—ì„œ ë‰´ìŠ¤ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤...")
    for url in GOOGLE_ALERTS_RSS_URLS:
        if not url.strip(): continue
        try:
            feed = feedparser.parse(url)
            for entry in feed.entries:
                raw_link = entry.link.split("&url=")[1] if "&url=" in entry.link else entry.link
                final_link = get_final_url(raw_link)
                published_date = datetime.datetime(*entry.published_parsed[:6]).strftime('%Y-%m-%d') if hasattr(entry, 'published_parsed') else "ë‚ ì§œ ì •ë³´ ì—†ìŒ"
                news_list.append({"title": entry.title, "link": final_link, "published": published_date, "source": "Google Alerts"})
        except Exception as e:
            print(f"  (ê²½ê³ ) êµ¬ê¸€ ì•Œë¦¬ë¯¸ RSS ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨ ({url}): {e}")

    print("- Naver Newsì—ì„œ ë‰´ìŠ¤ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤...")
    for query in NAVER_QUERIES:
        if not query.strip(): continue
        try:
            naver_url = "https://openapi.naver.com/v1/search/news.json"
            headers = {"X-Naver-Client-Id": NAVER_CLIENT_ID, "X-Naver-Client-Secret": NAVER_CLIENT_SECRET}
            params = {"query": query, "display": 10, "sort": "date"}
            response = requests.get(naver_url, headers=headers, params=params)
            response.raise_for_status()
            data = response.json()
            for item in data.get("items", []):
                clean_title = re.sub('<[^>]*>', '', item["title"])
                published_date = datetime.datetime.strptime(item['pubDate'], '%a, d %b %Y %H:%M:%S +0900').strftime('%Y-%m-%d')
                raw_link = item.get("originallink", item["link"])
                news_list.append({"title": clean_title, "link": raw_link, "published": published_date, "source": "Naver News"})
        except Exception as e:
            print(f"  (ê²½ê³ ) ë„¤ì´ë²„ ë‰´ìŠ¤ API ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨ ({query}): {e}")

    # 1ì°¨ ì¤‘ë³µ ì œê±°: URL ê¸°ì¤€
    news_list.sort(key=lambda x: x['published'], reverse=True)
    unique_news_items = []
    seen_links = set()

    for item in news_list:
        # HTML íƒœê·¸ ì œê±° ë° ì œëª© ì •ì œ
        item['title'] = re.sub('<[^>]*>', '', item['title'])
        normalized_link = re.sub(r'^https?:\/\/(www\.)?', '', item['link']).rstrip('/')
        if normalized_link not in seen_links:
            unique_news_items.append(item)
            seen_links.add(normalized_link)
            
    return unique_news_items

# ==============================================================================
# --- 3. AI ë‰´ìŠ¤ ì„ ë³„ í•¨ìˆ˜ (âœ¨ ì¤‘ë³µ ì œê±° ë¡œì§ ê°•í™”) ---
# ==============================================================================
def filter_news_by_ai(news_items):
    """AIë¥¼ ì‚¬ìš©í•´ ì˜ë¯¸ì ìœ¼ë¡œ ì¤‘ë³µë˜ëŠ” ë‰´ìŠ¤ë¥¼ ì œê±°í•˜ê³ , ì •ì±… ì…ì•ˆìì—ê²Œ ì¤‘ìš”í•œ ë‰´ìŠ¤ë¥¼ ì„ ë³„í•˜ëŠ” í•¨ìˆ˜"""
    print("\n[ğŸš€ ì‘ì—… ì¤‘] AIê°€ ì˜ë¯¸ ê¸°ë°˜ìœ¼ë¡œ ë‰´ìŠ¤ë¥¼ ë¶„ì„í•˜ì—¬ ì¤‘ë³µì„ ì œê±°í•˜ê³  í•µì‹¬ ë‰´ìŠ¤ë¥¼ ì„ ë³„í•©ë‹ˆë‹¤...")
    if not OPENAI_API_KEY or not OPENAI_API_KEY.startswith("sk-"):
        print("  (ê²½ê³ ) OpenAI API í‚¤ê°€ ì—†ì–´ ë‰´ìŠ¤ ì„ ë³„ì„ ê±´ë„ˆë›°ê³  ìµœì‹  ë‰´ìŠ¤ 20ê°œë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.")
        return news_items[:20]

    client = openai.OpenAI(api_key=OPENAI_API_KEY)
    formatted_news_list = ""
    for i, item in enumerate(news_items):
        formatted_news_list += f"[{i}] {item['title']}\n"

    prompt = f"""
    ë‹¹ì‹ ì€ ICT í‘œì¤€ ì •ì±… ìµœê³  ì „ë¬¸ê°€ì˜ ìˆ˜ì„ ë³´ì¢Œê´€ì…ë‹ˆë‹¤.
    ë‹¹ì‹ ì˜ ì„ë¬´ëŠ” ì•„ë˜ ë‰´ìŠ¤ ëª©ë¡ì—ì„œ ì˜ë¯¸ì ìœ¼ë¡œ ì¤‘ë³µë˜ëŠ” ê¸°ì‚¬ë¥¼ ì™„ë²½í•˜ê²Œ ì œê±°í•œ ë’¤, 'í‘œì¤€ ì •ì±… ì…ì•ˆì'ì˜ ê´€ì ì—ì„œ ê°€ì¥ ì¤‘ìš”í•œ ë‰´ìŠ¤ 20ê°œë¥¼ ì„ ë³„í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

    [ì‘ì—… ì ˆì°¨]
    1. **ì˜ë¯¸ ê¸°ë°˜ ì¤‘ë³µ ì œê±° (ê°€ì¥ ì¤‘ìš”)**: ì•„ë˜ ë‰´ìŠ¤ ëª©ë¡ì„ ì£¼ì˜ ê¹Šê²Œ ì½ê³ , ì œëª©ì˜ í‘œí˜„ì´ ì¡°ê¸ˆ ë‹¤ë¥´ë”ë¼ë„ ì‚¬ì‹¤ìƒ 'ë™ì¼í•œ ì‚¬ê±´'ì´ë‚˜ 'ë™ì¼í•œ ì£¼ì œ'ë¥¼ ë‹¤ë£¨ëŠ” ê¸°ì‚¬ë“¤ì„ ëª¨ë‘ ì°¾ì•„ë‚´ì„¸ìš”. ê° ì¤‘ë³µ ê·¸ë£¹ì—ì„œ ê°€ì¥ ëŒ€í‘œì ì¸ ê¸°ì‚¬ **í•˜ë‚˜ë§Œ** ë‚¨ê¸°ê³  ë‚˜ë¨¸ì§€ëŠ” ëª¨ë‘ ì œê±°í•©ë‹ˆë‹¤.
       - ì˜ˆì‹œ 1: "[ì „ìíŒŒí•™íšŒ] ì´ì¬ì„± í•™íšŒì¥ '6G ìœ„ì„±...'" ê³¼ "[ì „ìíŒŒí•™íšŒ] K-ì „íŒŒ, 6G ìœ„ì„±Â·ìš°ì£¼êµ­ë°©..." ì€ ë™ì¼í•œ í–‰ì‚¬ ê¸°ì‚¬ì´ë¯€ë¡œ í•˜ë‚˜ë§Œ ì„ íƒí•©ë‹ˆë‹¤.
       - ì˜ˆì‹œ 2: "ì •ë¶€, '5GíŠ¹í™”ë§2.0' ì¶”ì§„..." ê³¼ "ì •ë¶€, ì „íŒŒì§„í¥ê³„íš êµ¬ì²´í™”..." ê°€ ë™ì¼í•œ ì •ì±… ë°œí‘œë¼ë©´ í•˜ë‚˜ë§Œ ì„ íƒí•©ë‹ˆë‹¤.
    2. **ìµœì¢… ì„ ë³„**: ì¤‘ë³µì´ ì™„ë²½íˆ ì œê±°ëœ ë‰´ìŠ¤ ëª©ë¡ì—ì„œ, ì•„ë˜ [ì„ ë³„ ìµœìš°ì„  ê¸°ì¤€]ì— ë”°ë¼ ì •ì±…ì  ì¤‘ìš”ë„ê°€ ê°€ì¥ ë†’ì€ ë‰´ìŠ¤ 20ê°œë¥¼ ìµœì¢…ì ìœ¼ë¡œ ì„ ë³„í•©ë‹ˆë‹¤.

    [ì„ ë³„ ìµœìš°ì„  ê¸°ì¤€]
    - **í•´ì™¸ ì£¼ìš”êµ­ ì •ì±…/ê·œì œ**: ë¯¸êµ­(FCC), ìœ ëŸ½(ETSI), ì˜êµ­(Ofcom) ë“±ì˜ ë²•ì•ˆ, ê·œì œ, ì •ì±… ë³€í™”
    - **êµ­ì œ í‘œì¤€í™” ë™í–¥**: 3GPP, ITU, IEEE ë“±ì˜ ì˜ì‚¬ê²°ì •, ì°¨ì„¸ëŒ€ ê¸°ìˆ (6G, AI, ìœ„ì„±í†µì‹ ) í‘œì¤€í™” ë°©í–¥
    - **êµ­ë‚´ ì •ë¶€ ê³„íš ë° ë°œí‘œ**: ê³¼ê¸°ì •í†µë¶€, ë°©í†µìœ„ ë“±ì˜ í•µì‹¬ ì •ì±…, ë²•Â·ì œë„ ê°œì •, êµ­ê°€ R&D ì „ëµ
    - **ì‚°ì—…ê³„ í•µì‹¬ ë™í–¥**: ICT ì‚°ì—… íŒë„ì— ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” êµ­ë‚´ì™¸ ê¸°ì—…ì˜ ê¸°ìˆ  ê°œë°œ ë° ì‚¬ì—… ì „ëµ
    - **TTA ê´€ë ¨ ë³´ë„**: TTA ê³µì‹ ë³´ë„ìë£Œ, ì£¼ìš” ì¸ì‚¬ ë°œì–¸, ì¸í„°ë·° ë“±

    [ë‰´ìŠ¤ ëª©ë¡]
    {formatted_news_list}

    [ìš”ì²­]
    ìœ„ ì ˆì°¨ì™€ ê¸°ì¤€ì— ë”°ë¼ ìµœì¢…ì ìœ¼ë¡œ ì„ ë³„ëœ ë‰´ìŠ¤ì˜ ë²ˆí˜¸(ì¸ë±ìŠ¤) 20ê°œë§Œ ì‰¼í‘œ(,)ë¡œ êµ¬ë¶„í•˜ì—¬ ì‘ë‹µí•´ ì£¼ì‹­ì‹œì˜¤.
    ë‹¤ë¥¸ ì„¤ëª…ì´ë‚˜ í…ìŠ¤íŠ¸ëŠ” ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ê³ , ë²ˆí˜¸ë§Œ ì‘ë‹µí•´ì•¼ í•©ë‹ˆë‹¤.
    ì˜ˆì‹œ: 3, 8, 12, 15, 21, 23, 25, 30, 31, 33, 40, 41, 42, 45, 50, 51, 52, 53, 54, 55
    """

    try:
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ICT í‘œì¤€ ì •ì±… ì „ë¬¸ê°€ì˜ ìœ ëŠ¥í•œ ë³´ì¢Œê´€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ë‰´ìŠ¤ ëª©ë¡ì—ì„œ ì˜ë¯¸ì ìœ¼ë¡œ ì¤‘ë³µë˜ëŠ” ê²ƒì„ ì™„ë²½íˆ ì œê±°í•˜ê³ , ì •ì±…ì  ì¤‘ìš”ë„ê°€ ê°€ì¥ ë†’ì€ 20ê°œë¥¼ ê³¨ë¼ ë²ˆí˜¸ë§Œ ì‘ë‹µí•©ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.0,
        )
        selected_indices_str = response.choices[0].message.content
        print(f"  > AIê°€ ì„ ë³„í•œ ìµœì¢… ë‰´ìŠ¤ ì¸ë±ìŠ¤: {selected_indices_str}")
        
        # ì •ê·œì‹ì„ ì‚¬ìš©í•˜ì—¬ ì‘ë‹µì—ì„œ ìˆ«ìë§Œ ì¶”ì¶œ (ì•ˆì •ì„± ê°•í™”)
        indices = re.findall(r'\d+', selected_indices_str)
        selected_indices = [int(i) for i in indices]
        
        filtered_news = [news_items[i] for i in selected_indices if i < len(news_items)]
        if not filtered_news: raise ValueError("AIê°€ ìœ íš¨í•œ ì¸ë±ìŠ¤ë¥¼ ë°˜í™˜í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return filtered_news
    except Exception as e:
        print(f"  (ê²½ê³ ) AI ë‰´ìŠ¤ ì„ ë³„ ì‹¤íŒ¨: {e}. ìµœì‹  ë‰´ìŠ¤ 20ê°œë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
        return news_items[:20]

# ==============================================================================
# --- 4. AI ì‹¬ì¸µ ë¶„ì„ í•¨ìˆ˜ (ë³´ê³ ì„œ í˜•ì‹ êµ¬ì²´í™”) ---
# ==============================================================================
def analyze_news_with_ai(news_item):
    """AIì—ê²Œ ë‰´ìŠ¤ë¥¼ ë³´ë‚´ êµ¬ì²´í™”ëœ ì „ë¬¸ê°€ ë³´ê³ ì„œ í˜•ì‹ìœ¼ë¡œ ì‹¬ì¸µ ë¶„ì„ì„ ìš”ì²­í•˜ëŠ” í•¨ìˆ˜"""
    if not OPENAI_API_KEY or not OPENAI_API_KEY.startswith("sk-"):
        return "OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ ë¶„ì„ì„ ê±´ë„ˆëœë‹ˆë‹¤."
        
    client = openai.OpenAI(api_key=OPENAI_API_KEY)
    prompt = f"""
    ë‹¹ì‹ ì€ 20ë…„ ê²½ë ¥ì˜ ICT í‘œì¤€ ë° ì •ì±… ë¶„ì•¼ ìµœê³  ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
    ì•„ë˜ ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ ë¶„ì„í•˜ì—¬, ë‹¤ìŒ 4ê°€ì§€ í•­ëª©ìœ¼ë¡œ êµ¬ì„±ëœ ì „ë¬¸ê°€ ë³´ê³ ì„œë¥¼ ì‘ì„±í•´ ì£¼ì‹­ì‹œì˜¤.
    ëª¨ë“  ë‚´ìš©ì€ ì¤‘í•™ìƒë„ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ëª…í™•í•˜ê³  ì‰¬ìš´ ì–¸ì–´ë¥¼ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.

    [ë‰´ìŠ¤ ì •ë³´]
    - ë‰´ìŠ¤ ì œëª©: {news_item['title']}
    - ì›ë¬¸ ë§í¬: {news_item['link']}

    [ë³´ê³ ì„œ ì‘ì„± í˜•ì‹]
    - **ì£¼ìš” ë‚´ìš©:** (ê¸°ì‚¬ì˜ í•µì‹¬ ì‚¬ì‹¤ê³¼ ì •ë³´ë¥¼ í•œ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•œ ë’¤, 3ê°œì˜ ê¸€ë¨¸ë¦¬ ê¸°í˜¸(bullet point)ë¡œ ìƒì„¸ ì •ë¦¬)
      - 
      - 
      - 
    - **ì‹œì‚¬ì  ë° ì „ë§:** (ì´ ë‰´ìŠ¤ê°€ ICT í‘œì¤€, ê·œì œ, ì‹œì¥ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ê³¼ í–¥í›„ ì „ë§ì„ í•œ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•œ ë’¤, 3ê°œì˜ ê¸€ë¨¸ë¦¬ ê¸°í˜¸(bullet point)ë¡œ ìƒì„¸ ë¶„ì„)
      - 
      - 
      - 
    """
    try:
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ICT í‘œì¤€ ì •ì±… ë¶„ì„ ìµœê³  ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ëª¨ë“  ë‹µë³€ì€ 'ì£¼ìš” ë‚´ìš©', 'ì‹œì‚¬ì  ë° ì „ë§' ê°ê°ì— ëŒ€í•´ í•œ ë¬¸ì¥ ìš”ì•½ê³¼ 3ê°œì˜ ê¸€ë¨¸ë¦¬ ê¸°í˜¸ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.5, max_tokens=1024,
        )
        return response.choices[0].message.content
    except Exception as e:
        print(f"  (ê²½ê³ ) AI ì‹¬ì¸µ ë¶„ì„ ì‹¤íŒ¨ ({news_item['title']}): {e}")
        return "AI ì‹¬ì¸µ ë¶„ì„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."

# ==============================================================================
# --- 5. êµ¬ê¸€ ë¬¸ì„œ ìƒì„± í•¨ìˆ˜ (API ì˜¤ë¥˜ ìˆ˜ì •) ---
# ==============================================================================
def get_google_services():
    """Google Docsì™€ Drive API ì„œë¹„ìŠ¤ë¥¼ ì¸ì¦í•˜ê³  ìƒì„±í•˜ëŠ” í•¨ìˆ˜"""
    creds = None
    if os.path.exists('token.json'):
        creds = Credentials.from_authorized_user_file('token.json', SCOPES)
    if not creds or not creds.valid:
        if creds and creds.expired and creds.refresh_token:
            try:
                creds.refresh(Request())
            except Exception as e:
                print(f" (ì •ë³´) í† í° ê°±ì‹  ì‹¤íŒ¨: {e}. 'token.json'ì„ ì‚­ì œí•˜ê³  ë‹¤ì‹œ ì¸ì¦ì„ ì‹œë„í•©ë‹ˆë‹¤.")
                if os.path.exists('token.json'):
                    os.remove('token.json')
                creds = None
    
    if not creds:
        flow = InstalledAppFlow.from_client_secrets_file('credentials.json', SCOPES)
        creds = flow.run_local_server(port=0)
        with open('token.json', 'w') as token:
            token.write(creds.to_json())
            
    docs_service = build('docs', 'v1', credentials=creds)
    drive_service = build('drive', 'v3', credentials=creds)
    return docs_service, drive_service

def generate_google_doc_report(analyzed_data):
    try:
        docs_service, drive_service = get_google_services()
    except FileNotFoundError:
        print("  (ì˜¤ë¥˜) 'credentials.json' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. êµ¬ê¸€ ì¸ì¦ ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš”.")
        return None, None
    except Exception as e:
        print(f"  (ì˜¤ë¥˜) êµ¬ê¸€ ì„œë¹„ìŠ¤ ì—°ê²°ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}")
        return None, None
        
    current_date = datetime.date.today().strftime('%Yë…„ %mì›” %dì¼')
    document_title = f"ICT ì£¼ìš” ê¸°ìˆ  ë™í–¥ ë³´ê³ ì„œ ({current_date})"
    
    try:
        # 1. ë¬¸ì„œ ìƒì„±
        document = docs_service.documents().create(body={'title': document_title}).execute()
        document_id = document.get('documentId')
        document_url = f"https://docs.google.com/document/d/{document_id}/edit"
        print(f"  > ìƒˆ ë¬¸ì„œê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤: {document_url}")

        # 2. ìŠ¤íƒ€ì¼ë§ëœ ë‚´ìš© ì¶”ê°€
        requests = []
        index = 1

        # --- ë¬¸ì„œ ì œëª© ìŠ¤íƒ€ì¼ë§ ---
        title_text = f"{document_title}\n"
        requests.append({'insertText': {'location': {'index': index}, 'text': title_text}})
        requests.append({'updateParagraphStyle': {'range': {'startIndex': index, 'endIndex': index + len(title_text)}, 'paragraphStyle': {'alignment': 'CENTER'}, 'fields': 'alignment'}})
        requests.append({'updateTextStyle': {'range': {'startIndex': index, 'endIndex': index + len(title_text) - 1}, 'textStyle': {'fontSize': {'magnitude': 18, 'unit': 'PT'}, 'bold': True}, 'fields': 'fontSize,bold'}})
        index += len(title_text)
        
        # --- AI ë¶„ì„ ê³ ì§€ ë¬¸êµ¬ ---
        disclaimer_text = "â€» ë³¸ ë³´ê³ ì„œì˜ ë‚´ìš©ì€ AIê°€ ìƒì„±í•œ ë¶„ì„ìœ¼ë¡œ, ê°œì¸ì ì¸ ì˜ê²¬ì„ í¬í•¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n\n"
        requests.append({'insertText': {'location': {'index': index}, 'text': disclaimer_text}})
        requests.append({'updateParagraphStyle': {'range': {'startIndex': index, 'endIndex': index + len(disclaimer_text)}, 'paragraphStyle': {'alignment': 'CENTER'}, 'fields': 'alignment'}})
        requests.append({'updateTextStyle': {'range': {'startIndex': index, 'endIndex': index + len(disclaimer_text) - 2}, 'textStyle': {'fontSize': {'magnitude': 9, 'unit': 'PT'}, 'italic': True, 'foregroundColor': {'color': {'rgbColor': {'red': 0.5, 'green': 0.5, 'blue': 0.5}}}}, 'fields': 'fontSize,italic,foregroundColor'}})
        index += len(disclaimer_text)


        # --- ê° ë‰´ìŠ¤ ì•„ì´í…œ ìŠ¤íƒ€ì¼ë§ ---
        for i, data in enumerate(analyzed_data):
            # ë‰´ìŠ¤ ì œëª©
            news_title = f"[{i+1}] {data['title']}\n"
            requests.append({'insertText': {'location': {'index': index}, 'text': news_title}})
            requests.append({'updateTextStyle': {'range': {'startIndex': index, 'endIndex': index + len(news_title)}, 'textStyle': {'fontSize': {'magnitude': 14, 'unit': 'PT'}, 'bold': True}, 'fields': 'fontSize,bold'}})
            index += len(news_title)
            
            # ë©”íƒ€ë°ì´í„° (ì¶œì²˜, ë°œí–‰ì¼, ë§í¬)
            meta_text = f"ì¶œì²˜: {data['source']} | ë°œí–‰ì¼: {data['published']}\n"
            requests.append({'insertText': {'location': {'index': index}, 'text': meta_text}})
            requests.append({'updateTextStyle': {'range': {'startIndex': index, 'endIndex': index + len(meta_text)}, 'textStyle': {'fontSize': {'magnitude': 9, 'unit': 'PT'}, 'foregroundColor': {'color': {'rgbColor': {'red': 0.5, 'green': 0.5, 'blue': 0.5}}}}, 'fields': 'fontSize,foregroundColor'}})
            index += len(meta_text)
            
            link_text = f"ì›ë³¸ ë§í¬: {data['link']}\n\n"
            requests.append({'insertText': {'location': {'index': index}, 'text': link_text}})
            requests.append({'updateTextStyle': {'range': {'startIndex': index, 'endIndex': index + len(link_text)}, 'textStyle': {'fontSize': {'magnitude': 9, 'unit': 'PT'}, 'link': {'url': data['link']}}, 'fields': 'fontSize,link'}})
            index += len(link_text)

            # ë¶„ì„ ë‚´ìš© íŒŒì‹± (ì •ê·œì‹ ìˆ˜ì •)
            analysis_text = data.get('analysis_result', '')
            main_content_match = re.search(r'\*\*(ì£¼ìš” ë‚´ìš©):\*\*\s*(.*?)(?=\s*\*\*|\Z)', analysis_text, re.DOTALL)
            implications_match = re.search(r'\*\*(ì‹œì‚¬ì  ë° ì „ë§):\*\*\s*(.*?)(?=\s*\*\*|\Z)', analysis_text, re.DOTALL)
            main_content = main_content_match.group(2).strip() if main_content_match else "ì£¼ìš”ë‚´ìš© ì •ë³´ ì—†ìŒ"
            implications = implications_match.group(2).strip() if implications_match else "ì‹œì‚¬ì  ì •ë³´ ì—†ìŒ"

            # ì£¼ìš” ë‚´ìš© ì„¹ì…˜ (íƒ€ì´í‹€ ìˆ˜ì •)
            main_content_title = "ì£¼ìš” ë‚´ìš©\n"
            requests.append({'insertText': {'location': {'index': index}, 'text': main_content_title}})
            requests.append({'updateTextStyle': {'range': {'startIndex': index, 'endIndex': index + len(main_content_title)}, 'textStyle': {'bold': True}, 'fields': 'bold'}})
            requests.append({'updateParagraphStyle': {'range': {'startIndex': index, 'endIndex': index + len(main_content_title)}, 'paragraphStyle': {'shading': {'backgroundColor': {'color': {'rgbColor': {'red': 0.91, 'green': 0.95, 'blue': 1.0}}}}}, 'fields': 'shading'}})
            index += len(main_content_title)
            
            main_content_body = f"{main_content}\n\n"
            requests.append({'insertText': {'location': {'index': index}, 'text': main_content_body}})
            index += len(main_content_body)
            
            print(main_content_body)

            # ì‹œì‚¬ì  ë° ì „ë§ ì„¹ì…˜
            implications_title = "ì‹œì‚¬ì  ë° ì „ë§\n"
            requests.append({'insertText': {'location': {'index': index}, 'text': implications_title}})
            requests.append({'updateTextStyle': {'range': {'startIndex': index, 'endIndex': index + len(implications_title)}, 'textStyle': {'bold': True}, 'fields': 'bold'}})
            requests.append({'updateParagraphStyle': {'range': {'startIndex': index, 'endIndex': index + len(implications_title)}, 'paragraphStyle': {'shading': {'backgroundColor': {'color': {'rgbColor': {'red': 1.0, 'green': 0.96, 'blue': 0.9}}}}}, 'fields': 'shading'}})
            index += len(implications_title)

            implications_body = f"{implications}\n\n"
            requests.append({'insertText': {'location': {'index': index}, 'text': implications_body}})
            index += len(implications_body)

        # 3. ì¼ê´„ ì—…ë°ì´íŠ¸ ì‹¤í–‰
        docs_service.documents().batchUpdate(documentId=document_id, body={'requests': requests}).execute()
        
        return document_url, document_title
    except Exception as e:
        print(f"  (ì˜¤ë¥˜) êµ¬ê¸€ ë¬¸ì„œ ìƒì„±/ìŠ¤íƒ€ì¼ë§ ì‹¤íŒ¨: {e}")
        return None, None

# ==============================================================================
# --- 6. Gmail ì „ì†¡ í•¨ìˆ˜ (í…œí”Œë¦¿ ë° íŒŒì‹± ë¡œì§ ìˆ˜ì •) ---
# ==============================================================================
def send_gmail_report(report_title, analyzed_data, doc_url, other_news):
    # ... (ìƒëµ) ...
    news_items_html = ""
    for i, data in enumerate(analyzed_data):
        # ... (ë¶„ì„ ê²°ê³¼ íŒŒì‹± ë¡œì§) ...

        # âœ… í•´ê²°ì±…: += ì—°ì‚°ìë¥¼ ì‚¬ìš©í•˜ì—¬ HTML ë‚´ìš©ì„ ê³„ì† ëˆ„ì í•©ë‹ˆë‹¤.
        news_items_html += f"""
        <div class="news-item">
            <div class="news-header">
                <h3 class="news-title">[{i+1}] {data['title']}</h3>
                <div class="news-meta">
                    <span><strong>ì¶œì²˜:</strong> {data['source']}</span>
                    <span><strong>ë°œí–‰ì¼:</strong> {data['published']}</span>
                    <span><a href="{data['link']}" target="_blank">ì›ë¬¸ ê¸°ì‚¬ ë³´ê¸° &rarr;</a></span>
                </div>
            </div>
            <div class="analysis-container">
                <div class="analysis-section summary">
                    <div class="analysis-title"><span class="icon">ğŸ“</span><strong>ì£¼ìš” ë‚´ìš©</strong></div>
                    <p class="analysis-text">{main_content.replace('\n', '<br>')}</p>
                </div>
                <div class="analysis-section implications">
                    <div class="analysis-title"><span class="icon">ğŸ’¡</span><strong>ì‹œì‚¬ì  ë° ì „ë§</strong></div>
                    <p class="analysis-text">{implications.replace('\n', '<br>')}</p>
                </div>
            </div>
        </div>"""

    # 2. ê¸°íƒ€ ë‰´ìŠ¤ HTML ìƒì„± (ë³€ê²½ ì—†ìŒ)
    other_news_html = ""
    if other_news:
        other_news_html += """
        <div class="other-news-section">
            <h2>ê¸°íƒ€ ìˆ˜ì§‘ëœ ë‰´ìŠ¤</h2>
            <ul class="other-news-list">
        """
        for item in other_news:
            other_news_html += f'<li><a href="{item["link"]}" target="_blank" class="other-news-link"><span class="other-news-title">{item["title"]}</span><span class="other-news-source">({item["source"]})</span></a></li>'
        
        other_news_html += "</ul></div>"


    # 3. ì „ì²´ ì´ë©”ì¼ ë³¸ë¬¸ ì¡°í•© (í…œí”Œë¦¿ ìˆ˜ì •)
    html_body = f"""
    <!DOCTYPE html>
    <html lang="ko"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><title>ICT ì£¼ìš”ê¸°ìˆ  ë™í–¥ ë¦¬í¬íŠ¸</title>
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Noto+Sans+KR:wght@300;400;500;700&display=swap');
        body {{ margin: 0; padding: 0; background-color: #f4f7fa; font-family: 'Noto Sans KR', sans-serif; }}
        .email-container {{ max-width: 700px; margin: 20px auto; background-color: #ffffff; border-radius: 12px; overflow: hidden; box-shadow: 0 10px 40px rgba(0, 0, 0, 0.05); border: 1px solid #e9e9e9; }}
        .header {{ background: linear-gradient(135deg, #1D2B4A 0%, #2C3E6A 100%); color: #ffffff; padding: 40px; text-align: center; }}
        .header h1 {{ margin: 0; font-size: 28px; font-weight: 700; }} .header p {{ margin: 8px 0 0; font-size: 16px; font-weight: 300; opacity: 0.8; }}
        .disclaimer {{ font-size: 12px; opacity: 0.7; font-style: italic; margin-top: 15px;}}
        .main-content {{ padding: 40px; }}
        .report-intro {{ text-align: center; padding-bottom: 30px; border-bottom: 1px solid #eaeaea; margin-bottom: 30px; }}
        .button {{ display: inline-block; background: linear-gradient(135deg, #4A6DFF 0%, #6284FF 100%); color: #ffffff; padding: 14px 28px; border-radius: 50px; text-decoration: none; font-weight: 500; font-size: 15px; transition: all 0.3s ease; box-shadow: 0 4px 15px rgba(74, 109, 255, 0.3); }}
        .button:hover {{ transform: translateY(-2px); box-shadow: 0 8px 25px rgba(74, 109, 255, 0.4); }}
        .news-item {{ border: 1px solid #e9e9e9; border-radius: 12px; margin-bottom: 25px; overflow: hidden; transition: all 0.3s ease; }}
        .news-item:hover {{ transform: translateY(-2px); box-shadow: 0 8px 25px rgba(0, 0, 0, 0.07); }}
        .news-header {{ padding: 25px; }} .news-title {{ font-size: 20px; font-weight: 700; color: #1D2B4A; margin: 0 0 15px; }}
        .news-meta {{ font-size: 13px; color: #777; }} .news-meta a {{ color: #4A6DFF; text-decoration: none; font-weight: 500; }} .news-meta span {{ margin-right: 15px; }}
        .analysis-container {{ padding: 0 25px 25px 25px; border-top: 1px solid #e9e9e9; background-color: #f8f9fc; }}
        .analysis-section {{ padding: 20px; border-radius: 8px; margin-top: 15px; }}
        .analysis-section.summary {{ background-color: #e9f3ff; border-left: 4px solid #4A6DFF; }}
        .analysis-section.implications {{ background-color: #fff6e9; border-left: 4px solid #ff9f43; }}
        .analysis-title {{ display: flex; align-items: center; font-size: 16px; font-weight: 700; color: #1D2B4A; margin-bottom: 10px; }}
        .analysis-title .icon {{ font-size: 20px; margin-right: 10px; }}
        .analysis-text {{ font-size: 14px; line-height: 1.7; color: #333; margin: 0; }}
        .other-news-section {{ margin-top: 40px; padding-top: 30px; border-top: 1px solid #eaeaea; }}
        .other-news-section h2 {{ font-size: 20px; font-weight: 700; color: #1D2B4A; margin-bottom: 20px; text-align: center; }}
        .other-news-list {{ list-style-type: none; padding: 0; margin: 0; }}
        .other-news-list li {{ border-radius: 8px; margin-bottom: 5px; border-left: 3px solid #ccc; background-color: #f8f9fc; transition: background-color 0.2s ease; }}
        .other-news-list li:hover {{ background-color: #f1f3f8; }}
        .other-news-link {{ display: flex; justify-content: space-between; align-items: center; padding: 12px 15px; text-decoration: none; color: inherit; }}
        .other-news-title {{ color: #333; font-size: 14px; }}
        .other-news-source {{ color: #888; font-size: 12px; white-space: nowrap; margin-left: 15px; }}
        .footer {{ text-align: center; padding: 30px; background-color: #f4f7fa; font-size: 13px; color: #999; }}
    </style></head>
    <body><div class="email-container">
        <div class="header"><h1>{report_title}</h1><p>ì˜¤ëŠ˜ì˜ í•µì‹¬ ê¸°ìˆ  ë‰´ìŠ¤ë¥¼ AIê°€ ë¶„ì„í•´ë“œë¦½ë‹ˆë‹¤.</p><p class="disclaimer">â€» ë³¸ ë³´ê³ ì„œì˜ ë‚´ìš©ì€ AIê°€ ìƒì„±í•œ ë¶„ì„ìœ¼ë¡œ, ê°œì¸ì ì¸ ì˜ê²¬ì„ í¬í•¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.</p></div>
        <div class="main-content">
            <div class="report-intro">
                <a href="{doc_url}" class="button" target="_blank">ğŸ“„ ì „ì²´ ë³´ê³ ì„œ ë³´ê¸°</a>
            </div>
            {news_items_html}
            {other_news_html}
        </div>
        <div class="footer"><p>ë³¸ ë¦¬í¬íŠ¸ëŠ” AI ê¸°ìˆ ì„ í™œìš©í•´ ìë™ ìƒì„±ëœ ë¶„ì„ ë³´ê³ ì„œì…ë‹ˆë‹¤.</p><p>Powered by Advanced IRONAGE AI Analytics</p></div>
    </div></body></html>"""

    msg = MIMEMultipart("alternative")
    msg["Subject"] = report_title
    msg["From"] = SENDER_EMAIL
    msg["To"] = ", ".join(RECEIVER_EMAIL)
    msg["Date"] = formatdate(localtime=True)
    msg.attach(MIMEText(html_body, 'html', 'utf-8'))
    
    try:
        server = smtplib.SMTP('smtp.gmail.com', 587)
        server.starttls()
        server.login(SENDER_EMAIL, GMAIL_PASSWORD)
        server.sendmail(SENDER_EMAIL, RECEIVER_EMAIL, msg.as_string())
        server.quit()
        print(f"  > âœ… ì´ë©”ì¼ì´ {', '.join(RECEIVER_EMAIL)} ì£¼ì†Œë¡œ ì„±ê³µì ìœ¼ë¡œ ë°œì†¡ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"  (ì˜¤ë¥˜) ì´ë©”ì¼ ë°œì†¡ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}")

# ==============================================================================
# --- 7. ë©”ì¸ ì‹¤í–‰ ë¶€ë¶„ (ê¸°ì¡´ê³¼ ë™ì¼) ---
# ==============================================================================
if __name__ == "__main__":
    print("==============================================")
    print("ğŸ¤– AI ë‰´ìŠ¤ ë¦¬í¬íŠ¸ ìë™ ìƒì„± ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.")
    print("==============================================")
    
    print("\n[ğŸš€ ì‘ì—… ì‹œì‘] ë‰´ìŠ¤ ìˆ˜ì§‘ ë° ì¤‘ë³µ ì œê±°ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
    unique_news_items = get_news_data()
    print(f"  > ì´ {len(unique_news_items)}ê°œì˜ ê³ ìœ í•œ ë‰´ìŠ¤ë¥¼ 1ì°¨ ìˆ˜ì§‘í–ˆìŠµë‹ˆë‹¤.")
    
    news_to_analyze = filter_news_by_ai(unique_news_items)
    print(f"  > AIê°€ ìµœì¢… ì„ ë³„í•œ {len(news_to_analyze)}ê°œì˜ í•µì‹¬ ë‰´ìŠ¤ë¥¼ ì‹¬ì¸µ ë¶„ì„í•©ë‹ˆë‹¤.")
    
    analyzed_links = {item['link'] for item in news_to_analyze}
    other_news = [item for item in unique_news_items if item['link'] not in analyzed_links]
    
    analyzed_results = []
    if news_to_analyze:
        print("\n[ğŸš€ ì‘ì—… ì¤‘] ì„ íƒëœ ë‰´ìŠ¤ì— ëŒ€í•œ ì‹¬ì¸µ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
        for i, item in enumerate(news_to_analyze):
            print(f"  ({i+1}/{len(news_to_analyze)}) ë¶„ì„ ì¤‘: {item['title'][:40]}...")
            analysis = analyze_news_with_ai(item)
            item['analysis_result'] = analysis
            analyzed_results.append(item)
            
    if analyzed_results:
        print("\n[ğŸš€ ì‘ì—… ì¤‘] êµ¬ê¸€ ë¬¸ì„œ ë³´ê³ ì„œë¥¼ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤...")
        generated_doc_url, report_title = generate_google_doc_report(analyzed_results)
        
        if report_title:
            print("\n[ğŸš€ ì‘ì—… ì¤‘] ìƒì„±ëœ ë¦¬í¬íŠ¸ë¥¼ ì´ë©”ì¼ë¡œ ë°œì†¡í•©ë‹ˆë‹¤...")
            send_gmail_report(report_title, analyzed_results, generated_doc_url, other_news)
            print("   (ì •ë³´) ì´ë©”ì¼ ë°œì†¡ì€ ì£¼ì„ ì²˜ë¦¬ë˜ì–´ ìˆìŠµë‹ˆë‹¤. í•„ìš” ì‹œ ì£¼ì„ì„ í•´ì œí•˜ì„¸ìš”.")

    print("\n==============================================")
    print("ğŸ‰ ëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    print("==============================================")





